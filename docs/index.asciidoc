:plugin: logstash-input-crowdstrike_fdr
:type: input
:default_codec: json

///////////////////////////////////////////
START - GENERATED VARIABLES, DO NOT EDIT!
///////////////////////////////////////////
:version: %VERSION%
:release_date: %RELEASE_DATE%
:changelog_url: %CHANGELOG_URL%
:include_path: ../../../../logstash/docs/include
///////////////////////////////////////////
END - GENERATED VARIABLES, DO NOT EDIT!
///////////////////////////////////////////

[id="plugins-{type}s-{plugin}"]

=== S3 input plugin (via SNS/SQS)

include::{include_path}/plugin_header.asciidoc[]

==== Description

.Compatibility Note
[NOTE]
================================================================================
Starting with Elasticsearch 5.3, there's an {ref}/modules-http.html[HTTP setting]
called `http.content_type.required`. If this option is set to `true`, and you
are using Logstash 2.4 through 5.2, you need to update the Elasticsearch input
plugin to version 4.0.2 or higher.

================================================================================

Read from an S3 bucket, based metadata read from an SQS Topic.
This is useful for reading files from an S3 bucket at scale with 
multiple logstash instances.

Example:
[source,ruby]
input {
  crowdstrike_fdr {
    region                     => "eu-central-1"
    s3_default_options         => { "endpoint_discovery" => true }
    queue                      => "logingest-sqs-queue"
    queue_owner_aws_account_id => "111111111111"
    type                       => "sqs-logs"
    tags                       => ["pa-alb-nonlive"]
    sqs_skip_delete            => true
    codec                      => json
    s3_options_by_bucket       => [
        { bucket_name => "logs-bucket-222222222222-.*"
          credentials => { role => "arn:aws:iam::222222222222:role/logging-role" }
        },
        { bucket_name => "logs-bucket-333333333333-eu-central-1"
          credentials => { role => "arn:aws:iam::333333333333:role/logging-role" }
          folders => [
          { key => ".*\/waflogs.*"
            codec => "json_stream"
            type => "waflogs"},
          { key => ".*\/2020"
            codec => "json_lines"
            type => "reports"}]
        }
    ]
  }
}
==== CrowdStrikeFDR Input Configuration Options

This plugin supports the following configuration options plus the <<plugins-{type}s-{plugin}-common-options>> described later.

[cols="<,<,<",options="header",]
|=======================================================================
|Setting |Input type|Required
| <<plugins-{type}s-{plugin}-queue>> |a valid queue name|Yes
| <<plugins-{type}s-{plugin}-delete_on_success>>|<<boolean,boolean>>|No
| <<plugins-{type}s-{plugin}-sqs_skip_delete>> |<<boolean,boolean>>|No
| <<plugins-{type}s-{plugin}-sqs_delete_on_failure>> |<<boolean,boolean>>|No
| <<plugins-{type}s-{plugin}-temporary_directory>> |<<string,string>>|No
| <<plugins-{type}s-{plugin}-consumer_threads>> |<<number,number>>|No
| <<plugins-{type}s-{plugin}-visibility_timeout>> |<<number,number>>|No
| <<plugins-{type}s-{plugin}-sqs_wait_time_seconds>> |<<number,number>>|No
| <<plugins-{type}s-{plugin}-max_processing_time>> |<<number,number>>|No
|=======================================================================

Also see <<plugins-{type}s-{plugin}-common-options>> for a list of options supported by all
input plugins.

&nbsp;

[id="plugins-{type}s-{plugin}-queue"]
===== `queue` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

a valid SQS queue name or queue url in new URL format:     https://github.com/aws/aws-sdk-ruby/issues/1620

e.g. https://sqs.us-west-1.amazonaws.com/.....


[id="plugins-{type}s-{plugin}-region"]
===== `region` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

AWS region for S3 operations

[id="plugins-{type}s-{plugin}-delete_on_success"]
===== `delete_on_success` 

  * Value type is <<boolean,boolean>>
  * The default value for this setting is FALSE.

delete files from S3 after success


[id="plugins-{type}s-{plugin}-sqs_skip_delete"]
===== `sqs_skip_delete` 

  * Value type is <<boolean,boolean>>
  * Default: false

Skip the delete on success of sqs messages e.g. for local debugging.
Messages will be requeued after visibility timeout.

[id="plugins-{type}s-{plugin}-sqs_delete_on_failure"]
===== `sqs_delete_on_failure`

  * Value type is <<boolean,boolean>>
  * The default value for this setting is FALSE.

Skip delete of sqs messages causing a hard error or timeout inside the poller and try again.
Maybe you are lucky...maybe you are not.

[id="plugins-{type}s-{plugin}-temporary_directory"]
===== `temporary_directory` 

  * Value type is <<string,string>>
  * There is no default value for this setting.

Your tmp dir

[id="plugins-{type}s-{plugin}-consumer_threads"]
===== `consumer_threads` 

  * Value type is <<number,number>>
  * Default: 1

How many SQS reader should be started

[id="plugins-{type}s-{plugin}-s3_role_arn"]

[id="plugins-{type}s-{plugin}-visibility_timeout"]
===== `visibility_timeout` 

  * Value type is <<number,number>>
  * Default: 5 Minutes.

The default visibility timeout for an SQS Message. If there is no
"exit 0, successful" from the code block the SQS message will be
reprocessed after reaching max_processing_time.

[id="plugins-{type}s-{plugin}-sqs_wait_time_seconds"]
===== `sqs_wait_time_seconds`

  * Value type is <<number,number>>
  * Default: NO.

Enable sqs long polling in seconds.
If not configured, the settings from your AWS SQS queue are respected.

[id="plugins-{type}s-{plugin}-max_processing_time"]
===== `max_processing_time`

  * Value type is <<number,number>>
  * Default: 8000 seconds

The hard limit processing an SQS/S3 message block

[id="plugins-{type}s-{plugin}-common-options"]
include::{include_path}/{type}.asciidoc[]

:default_codec!:
